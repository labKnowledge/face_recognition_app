<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <script type="module" crossorigin src="https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css" />
    <title>Face recognition App | Python on web 
    </title>
  </head>
  <body>
    <h1>Powered by gradio lite</h1>

    <gradio-lite>
        <gradio-requirements>
            opencv-python
            Pillow
        </gradio-requirements>
    
        <gradio-file name="main.py" entrypoint>
import gradio as gr
import cv2
import numpy as np
from PIL import Image


def interesting_filter(image):
    # Load the pre-trained age progression model (Age-cGAN)
    model = cv2.dnn.readNetFromCaffe("deploy_age.prototxt", "age_net.caffemodel")

    # Open the image using OpenCV
    img = cv2.imdecode(np.frombuffer(image.read(), np.uint8), -1)

    # Resize the image to the input size required by the model (256x256)
    input_blob = cv2.dnn.blobFromImage(img, 1.0, (256, 256), (0, 0, 0), swapRB=False, crop=False)

    # Set the input to the model and perform forward pass
    model.setInput(input_blob)
    output = model.forward()

    # Extract the age progression image from the output
    age_progression_img = output[0].transpose((1, 2, 0))

    # Convert the age progression image to PIL format
    pil_img = Image.fromarray(age_progression_img.astype(np.uint8))

    # Return the age progressed image
    return pil_img

def age_progression(image):
    # Load the pre-trained age progression model (Age-cGAN)
    model = cv2.dnn.readNetFromCaffe("deploy_age.prototxt", "age_net.caffemodel")

    # Open the image using OpenCV
    img = cv2.imdecode(np.frombuffer(image.read(), np.uint8), -1)

    # Resize the image to the input size required by the model (256x256)
    input_blob = cv2.dnn.blobFromImage(img, 1.0, (256, 256), (0, 0, 0), swapRB=False, crop=False)

    # Set the input to the model and perform forward pass
    model.setInput(input_blob)
    output = model.forward()

    # Extract the age progression image from the output
    age_progression_img = output[0].transpose((1, 2, 0))

    # Convert the age progression image to PIL format
    pil_img = Image.fromarray(age_progression_img.astype(np.uint8))

    # Return the age progressed image
    return pil_img

# Create the Gradio interface gr.Image()
gr.Interface(fn=age_progression, inputs=gr.Image(), outputs="image", title="Interesting Filter").launch()

        </gradio-file>
    </gradio-lite>



    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  </body>
</html>